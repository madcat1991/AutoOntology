Потратил несколько часов на написания инструмента для проверки, что более сложная грамматика работает лучше. Не сожалею насчет потраченного времени, так как смог найти слабые места и поправить пару багов.

Итак, слабое место уже в который раз pymorphy и nltk. NLTK делает POS-tagging не очень и не умеет работать с кривыми символами, ну т.е он считает их за букву. Pymorphy в свою очередь при нормализации возавращает множество ответов но при этом без приоритетов, что не позволяет выбрать самое подходящее. Возможно стоит задуматься насчет mystem, хотя, если я не ошибаюсь, он юзает те же библиотечки.

Дописал приведение к нормальной формуле. Теперь можно думать о том, как это дело хранить, какой текст брать и как кластеризировать. Посним, что кластеризация будет тяжелая и возможно стоит подумуть о кластере.